{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SARA3SAEED/aws-ML/blob/main/06_Precognition_Thinking_Step_by_Step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4_LzS0WLCkh"
      },
      "source": [
        "# Chapter 6: Precognition (Thinking Step by Step)\n",
        "\n",
        "- [Lesson](#lesson)\n",
        "- [Exercises](#exercises)\n",
        "- [Example Playground](#example-playground)\n",
        "\n",
        "## Setup\n",
        "\n",
        "Run the following setup cell to load your API key and establish the `get_completion` helper function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adoJg_WwLCkj"
      },
      "outputs": [],
      "source": [
        "# Import python's built-in regular expression library\n",
        "import re\n",
        "import boto3\n",
        "from botocore.exceptions import ClientError\n",
        "import json\n",
        "\n",
        "# Import the hints module from the utils package\n",
        "from utils import hints\n",
        "\n",
        "# Retrieve the MODEL_NAME variable from the IPython store\n",
        "%store -r modelId\n",
        "%store -r region\n",
        "\n",
        "bedrock_client = boto3.client(service_name='bedrock-runtime', region_name=region)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQ85p6KXLCkk"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, system_prompt=None, prefill=None):\n",
        "    inference_config = {\n",
        "        \"temperature\": 0.0,\n",
        "        \"maxTokens\": 200\n",
        "    }\n",
        "    converse_api_params = {\n",
        "        \"modelId\": modelId,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": [{\"text\": prompt}]}],\n",
        "        \"inferenceConfig\": inference_config,\n",
        "    }\n",
        "    if system_prompt:\n",
        "        converse_api_params[\"system\"] = [{\"text\": system_prompt}]\n",
        "    if prefill:\n",
        "        converse_api_params[\"messages\"].append({\"role\": \"assistant\", \"content\": [{\"text\": prefill}]})\n",
        "    try:\n",
        "        response = bedrock_client.converse(**converse_api_params)\n",
        "        text_content = response['output']['message']['content'][0]['text']\n",
        "        return text_content\n",
        "\n",
        "    except ClientError as err:\n",
        "        message = err.response['Error']['Message']\n",
        "        print(f\"A client error occured: {message}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ro2IYGi5LCkl"
      },
      "source": [
        "---\n",
        "\n",
        "## Lesson\n",
        "\n",
        "If someone woke you up and immediately started asking you several complicated questions that you had to respond to right away, how would you do? Probably not as good as if you were given time to **think through your answer first**.\n",
        "\n",
        "Guess what? Claude is the same way.\n",
        "\n",
        "**Giving Claude time to think step by step sometimes makes Claude more accurate**, particularly for complex tasks. However, **thinking only counts when it's out loud**. You cannot ask Claude to think but output only the answer - in this case, no thinking has actually occurred."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYCguBYkLCkl"
      },
      "source": [
        "### Examples\n",
        "\n",
        "In the prompt below, it's clear to a human reader that the second sentence belies the first. But **Claude takes the word \"unrelated\" too literally**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzJM_pmILCkm",
        "outputId": "422e0902-83c4-44b6-cd5b-0f1bb85785e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this movie review is positive.\n",
            "\n",
            "The review states that the movie \"blew my mind with its freshness and originality\", which indicates a very positive and enthusiastic reaction to the film.\n",
            "\n",
            "The second part of the review about living under a rock since 1900 is likely a humorous or sarcastic remark, but it does not negate the overall positive sentiment expressed about the movie's qualities.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
        "\n",
        "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9a4ATTvLCkn"
      },
      "source": [
        "To improve Claude's response, let's **allow Claude to think things out first before answering**. We do that by literally spelling out the steps that Claude should take in order to process and think through its task. Along with a dash of role prompting, this empowers Claude to understand the review more deeply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSo58y7XLCko",
        "outputId": "2c0e24f8-a537-4d4b-816d-d2eca70fdbb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<positive-argument>\n",
            "- The review suggests the movie was \"fresh\" and \"original,\" which are typically positive attributes for a film.\n",
            "- The reviewer was so impressed by the movie that it \"blew [their] mind,\" indicating a strong positive reaction.\n",
            "- The reviewer's comment about living \"under a rock since 1900\" could be interpreted as a self-deprecating acknowledgment that the movie's freshness and originality were new to them, rather than a criticism of the film itself.\n",
            "</positive-argument>\n",
            "\n",
            "<negative-argument>\n",
            "- The reviewer's statement about living \"under a rock since 1900\" could be seen as a criticism, implying that the movie's freshness and originality are not actually new or innovative, but rather something the reviewer is just now discovering.\n",
            "- The reviewer's tone could be interpreted as sarcastic or dismissive, suggesting that the positive attributes they mention are not genuine or sincere\n"
          ]
        }
      ],
      "source": [
        "# System prompt\n",
        "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
        "\n",
        "# Prompt\n",
        "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
        "\n",
        "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT, SYSTEM_PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmzzZLAbLCkp"
      },
      "source": [
        "**Claude is sometimes sensitive to ordering**. This example is on the frontier of Claude's ability to understand nuanced text, and when we swap the order of the arguments from the previous example so that negative is first and positive is second, this changes Claude's overall assessment to positive.\n",
        "\n",
        "In most situations (but not all, confusingly enough), **Claude is more likely to choose the second of two options**, possibly because in its training data from the web, second options were more likely to be correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFlWV6f1LCkp",
        "outputId": "06564c77-4566-4931-e767-63ab2fb7ec14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<negative-argument>\n",
            "The statement \"I have been living under a rock since 1900\" could be interpreted as a negative sentiment, suggesting that the reviewer has been out of touch with the world and may not be the best judge of the movie's freshness and originality. This could imply that the reviewer's opinion may not be reliable or well-informed.\n",
            "</negative-argument>\n",
            "\n",
            "<positive-argument>\n",
            "The review starts with a positive statement, describing the movie as having \"freshness and originality,\" which suggests a positive sentiment towards the film. The reviewer's acknowledgment of having been \"living under a rock since 1900\" could be seen as a humorous way of admitting their lack of exposure to recent media, which could make their praise for the movie's freshness and originality more meaningful.\n",
            "</positive-argument>\n",
            "\n",
            "Based on the overall tone and content of the review, the sentiment is more positive than negative. The positive\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then answer.\n",
        "\n",
        "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-THYYQlLCkp"
      },
      "source": [
        "**Letting Claude think can shift Claude's answer from incorrect to correct**. It's that simple in many cases where Claude makes mistakes!\n",
        "\n",
        "Let's go through an example where Claude's answer is incorrect to see how asking Claude to think can fix that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2a12RlofLCkq",
        "outputId": "e7332165-f635-4881-bf3c-2a99e5c2de3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a famous movie starring an actor born in 1956:\n",
            "\n",
            "The Shawshank Redemption (1994) starring Tim Robbins. Tim Robbins was born on October 16, 1958.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_nduhKZLCkq"
      },
      "source": [
        "Let's fix this by asking Claude to think step by step, this time in `<brainstorm>` tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvh971iLLCkq",
        "outputId": "c566fa64-3fbc-44e0-e611-bdd9baf9c292"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a brainstorm of some actors and their birth years:\n",
            "\n",
            "<brainstorm>\n",
            "- Tom Hanks (1956)\n",
            "- Denzel Washington (1954)\n",
            "- Julia Roberts (1967)\n",
            "- Harrison Ford (1942)\n",
            "- Meryl Streep (1949)\n",
            "</brainstorm>\n",
            "\n",
            "A famous movie starring an actor born in 1956 is:\n",
            "\n",
            "Forrest Gump, starring Tom Hanks.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQW00tO5LCkq"
      },
      "source": [
        "If you would like to experiment with the lesson prompts without changing any content above, scroll all the way to the bottom of the lesson notebook to visit the [**Example Playground**](#example-playground)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28alv93xLCkq"
      },
      "source": [
        "---\n",
        "\n",
        "## Exercises\n",
        "- [Exercise 6.1 - Classifying Emails](#exercise-61---classifying-emails)\n",
        "- [Exercise 6.2 - Email Classification Formatting](#exercise-62---email-classification-formatting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUi3pxWHLCkr"
      },
      "source": [
        "### Exercise 6.1 - Classifying Emails\n",
        "In this exercise, we'll be instructing Claude to sort emails into the following categories:\n",
        "- (A) Pre-sale question\n",
        "- (B) Broken or defective item\n",
        "- (C) Billing question\n",
        "- (D) Other (please explain)\n",
        "\n",
        "For the first part of the exercise, change the `PROMPT` to **make Claude output the correct classification and ONLY the classification**. Your answer needs to **include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category**.\n",
        "\n",
        "Refer to the comments beside each email in the `EMAILS` list to know which category that email should be classified under."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIRSedMMLCkr",
        "outputId": "a94406e9-1f79-4347-c1aa-9c24d714eec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content of the email, this would be classified as a \"blue\" email. The email describes a problem with a product (the Mixmaster4000) and requests a replacement, which indicates a customer service or technical support issue. This type of email would typically be handled by a \"blue\" team, which is responsible for addressing customer concerns and resolving product-related problems.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content of the email, this would be classified as a \"blue\" email. The question about using a Mixmaster 4000 to mix paint suggests this is not related to environmental or sustainability topics, which would be considered a \"green\" email. The inquiry about the intended use of the kitchen appliance is more of a general, practical question, not specifically about green or environmental issues.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the tone and content of the email, this would be classified as a \"blue\" email. The email is written in all capital letters, which conveys a sense of frustration and urgency. The language used, such as \"WTF is going on???\" also suggests an angry or upset tone. This type of email would typically be considered a \"blue\" email, indicating a negative emotional state and the need for a more empathetic and understanding response.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: How did I get here I am not good with computer.  Halp.\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content and tone of the email, I would classify it as a \"blue\" email. The email expresses confusion, uncertainty, and a request for help, which are typically characteristics of a \"blue\" email.\n",
            "\n",
            "The phrases \"How did I get here\" and \"I am not good with computer\" suggest the user is feeling lost or overwhelmed, and the use of \"Halp\" indicates they are seeking assistance in a more informal, casual manner. These elements are more indicative of a \"blue\" email rather than a \"green\" email, which would typically convey a more confident, problem-solving tone.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt template with a placeholder for the variable content\n",
        "PROMPT = \"\"\"Please classify this email as either green or blue: {email}\"\"\"\n",
        "\n",
        "# Prefill for Claude's response, if any\n",
        "PREFILL = \"\"\n",
        "\n",
        "# Variable content stored as a list\n",
        "EMAILS = [\n",
        "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
        "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
        "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
        "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
        "]\n",
        "\n",
        "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
        "ANSWERS = [\n",
        "    [\"B\"],\n",
        "    [\"A\",\"D\"],\n",
        "    [\"C\"],\n",
        "    [\"D\"]\n",
        "]\n",
        "\n",
        "# Dictionary of string values for each category to be used for regex grading\n",
        "REGEX_CATEGORIES = {\n",
        "    \"A\": \"A\\) P\",\n",
        "    \"B\": \"B\\) B\",\n",
        "    \"C\": \"C\\) B\",\n",
        "    \"D\": \"D\\) O\"\n",
        "}\n",
        "\n",
        "# Iterate through list of emails\n",
        "for i,email in enumerate(EMAILS):\n",
        "\n",
        "    # Substitute the email text into the email placeholder variable\n",
        "    formatted_prompt = PROMPT.format(email=email)\n",
        "\n",
        "    # Get Claude's response\n",
        "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
        "\n",
        "    # Grade Claude's response\n",
        "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
        "\n",
        "    # Print Claude's response\n",
        "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
        "    print(\"USER TURN\")\n",
        "    print(formatted_prompt)\n",
        "    print(\"\\nASSISTANT TURN\")\n",
        "    print(PREFILL)\n",
        "    print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
        "    print(response)\n",
        "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
        "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maByCCiJLCkr"
      },
      "source": [
        "❓ If you want a hint, run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIDrmkGcLCkr",
        "outputId": "905c32b1-1dc7-4370-89f2-c594bc197494"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The grading function in this exercise is looking for the correct categorization letter + the closing parentheses and the first letter of the name of the category, such as \"C) B\" or \"B) B\" etc.\n",
            "Let's take this exercise step by step:\t\t\t\t\t\t\t\t\t\t\n",
            "1.\tHow will Claude know what categories you want to use? Tell it! Include the four categories you want directly in the prompt. Be sure to include the parenthetical letters as well for easy classification. Feel free to use XML tags to organize your prompt and make clear to Claude where the categories begin and end.\t\t\t\t\t\t\t\t\t\n",
            "2.\tTry to cut down on superfluous text so that Claude immediately answers with the classification and ONLY the classification. There are several ways to do this, from speaking for Claude (providing anything from the beginning of the sentence to a single open parenthesis so that Claude knows you want the parenthetical letter as the first part of the answer) to telling Claude that you want the classification and only the classification, skipping the preamble.\n",
            "Refer to Chapters 2 and 5 if you want a refresher on these techniques.\t\t\t\t\t\t\t\n",
            "3.\tClaude may still be incorrectly categorizing or not including the names of the categories when it answers. Fix this by telling Claude to include the full category name in its answer.)\t\t\t\t\t\t\t\t\n",
            "4.\tBe sure that you still have {email} somewhere in your prompt template so that we can properly substitute in emails for Claude to evaluate.\n"
          ]
        }
      ],
      "source": [
        "print(hints.exercise_6_1_hint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2PvH86XLCks"
      },
      "source": [
        "Still stuck? Run the cell below for an example solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86pnnK1sLCks",
        "outputId": "74830eef-1625-4880-c07c-8a837e1466bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "USER TURN\n",
            "Please classify this email into the following categories: {email}\n",
            "\n",
            "Do not include any extra words except the category.\n",
            "\n",
            "<categories>\n",
            "(A) Pre-sale question\n",
            "(B) Broken or defective item\n",
            "(C) Billing question\n",
            "(D) Other (please explain)\n",
            "</categories>\n",
            "\n",
            "ASSISTANT TURN\n",
            "(\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(hints.exercise_6_1_solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtgbrnSaLCks"
      },
      "source": [
        "### Exercise 6.2 - Email Classification Formatting\n",
        "In this exercise, we're going to refine the output of the above prompt to yield an answer formatted exactly how we want it.\n",
        "\n",
        "Use your favorite output formatting technique to make Claude wrap JUST the letter of the correct classification in `<answer></answer>` tags. For instance, the answer to the first email should contain the exact string `<answer>B</answer>`.\n",
        "\n",
        "Refer to the comments beside each email in the `EMAILS` list if you forget which letter category is correct for each email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD6aC4B0LCks",
        "outputId": "eaeea39e-e3b7-4233-a8de-8e9d14cb7ab2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content of the email, this would be classified as a \"blue\" email. The email describes a technical issue with a product (the Mixmaster4000) and requests a replacement, which indicates a customer service or support request. This type of email would typically be handled by a customer service or technical support team, which is usually associated with the \"blue\" category of emails.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content of the email, this would be classified as a \"blue\" email. The question about using a Mixmaster 4000 to mix paint suggests it is not related to environmental or sustainability topics, which would be the focus of a \"green\" email.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the tone and content of the email, this would be classified as a \"blue\" email. The email is written in all capital letters, which conveys a sense of frustration and urgency. The language used, such as \"WTF is going on???\" also suggests an angry or upset tone. This type of email is typically associated with a negative customer experience or unresolved issue, which would be classified as a \"blue\" email.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "--------------------------- Full prompt with variable substutions ---------------------------\n",
            "USER TURN\n",
            "Please classify this email as either green or blue: How did I get here I am not good with computer.  Halp.\n",
            "\n",
            "ASSISTANT TURN\n",
            "\n",
            "\n",
            "------------------------------------- Claude's response -------------------------------------\n",
            "Based on the content and tone of the email, I would classify it as a \"blue\" email. The email expresses confusion, uncertainty, and a request for help, which are typically associated with a \"blue\" email.\n",
            "\n",
            "The phrases \"How did I get here\" and \"I am not good with computer\" suggest the user is feeling lost or overwhelmed, and the use of \"Halp\" indicates they are seeking assistance. These are characteristics more commonly found in \"blue\" emails, which tend to convey a sense of frustration, anxiety, or a need for support.\n",
            "\n",
            "In contrast, \"green\" emails are typically more positive, confident, and solution-oriented. They may express excitement, gratitude, or a clear understanding of the task at hand.\n",
            "\n",
            "------------------------------------------ GRADING ------------------------------------------\n",
            "This exercise has been correctly solved: False \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt template with a placeholder for the variable content\n",
        "PROMPT = \"\"\"Please classify this email as either green or blue: {email}\"\"\"\n",
        "\n",
        "# Prefill for Claude's response, if any\n",
        "PREFILL = \"\"\n",
        "\n",
        "# Variable content stored as a list\n",
        "EMAILS = [\n",
        "    \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\", # (B) Broken or defective item\n",
        "    \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\", # (A) Pre-sale question OR (D) Other (please explain)\n",
        "    \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\", # (C) Billing question\n",
        "    \"How did I get here I am not good with computer.  Halp.\" # (D) Other (please explain)\n",
        "]\n",
        "\n",
        "# Correct categorizations stored as a list of lists to accommodate the possibility of multiple correct categorizations per email\n",
        "ANSWERS = [\n",
        "    [\"B\"],\n",
        "    [\"A\",\"D\"],\n",
        "    [\"C\"],\n",
        "    [\"D\"]\n",
        "]\n",
        "\n",
        "# Dictionary of string values for each category to be used for regex grading\n",
        "REGEX_CATEGORIES = {\n",
        "    \"A\": \"<answer>A</answer>\",\n",
        "    \"B\": \"<answer>B</answer>\",\n",
        "    \"C\": \"<answer>C</answer>\",\n",
        "    \"D\": \"<answer>D</answer>\"\n",
        "}\n",
        "\n",
        "# Iterate through list of emails\n",
        "for i,email in enumerate(EMAILS):\n",
        "\n",
        "    # Substitute the email text into the email placeholder variable\n",
        "    formatted_prompt = PROMPT.format(email=email)\n",
        "\n",
        "    # Get Claude's response\n",
        "    response = get_completion(formatted_prompt, prefill=PREFILL)\n",
        "\n",
        "    # Grade Claude's response\n",
        "    grade = any([bool(re.search(REGEX_CATEGORIES[ans], response)) for ans in ANSWERS[i]])\n",
        "\n",
        "    # Print Claude's response\n",
        "    print(\"--------------------------- Full prompt with variable substutions ---------------------------\")\n",
        "    print(\"USER TURN\")\n",
        "    print(formatted_prompt)\n",
        "    print(\"\\nASSISTANT TURN\")\n",
        "    print(PREFILL)\n",
        "    print(\"\\n------------------------------------- Claude's response -------------------------------------\")\n",
        "    print(response)\n",
        "    print(\"\\n------------------------------------------ GRADING ------------------------------------------\")\n",
        "    print(\"This exercise has been correctly solved:\", grade, \"\\n\\n\\n\\n\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UVFRnJhLCkt"
      },
      "source": [
        "❓ If you want a hint, run the cell below!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWqD7tqJLCkt",
        "outputId": "2d5128a1-f87e-4bac-9430-786f66783650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The grading function in this exercise is looking for only the correct letter wrapped in <answer> tags, such as \"<answer>B</answer>\". The correct categorization letters are the same as in the above exercise.\n",
            "Sometimes the simplest way to go about this is to give Claude an example of how you want its output to look. Just don't forget to wrap your example in <example></example> tags! And don't forget that if you prefill Claude's response with anything, Claude won't actually output that as part of its response.\n"
          ]
        }
      ],
      "source": [
        "print(hints.exercise_6_2_hint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hi5xyzipLCkt"
      },
      "source": [
        "### Congrats!\n",
        "\n",
        "If you've solved all exercises up until this point, you're ready to move to the next chapter. Happy prompting!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB0E0kS4LCkt"
      },
      "source": [
        "---\n",
        "\n",
        "## Example Playground\n",
        "\n",
        "This is an area for you to experiment freely with the prompt examples shown in this lesson and tweak prompts to see how it may affect Claude's responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MMYKDi_LCkt",
        "outputId": "22d56edf-7030-48b6-c1e1-8efe81be4b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The sentiment of this movie review is positive.\n",
            "\n",
            "The review states that the movie \"blew my mind with its freshness and originality\", which indicates a very positive and enthusiastic reaction to the film.\n",
            "\n",
            "The second part of the review about living under a rock since 1900 is likely a humorous or sarcastic remark, but it does not negate the overall positive sentiment expressed in the first part of the review.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"\"\"Is this movie review sentiment positive or negative?\n",
        "\n",
        "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since the year 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq6KKHsbLCku",
        "outputId": "0874a3e7-a251-4dfe-d5fa-b07702e9695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<positive-argument>\n",
            "- The review suggests that the movie was highly innovative and unique, describing it as \"fresh and original\" and blowing the reviewer's mind.\n",
            "- The reviewer's comment about living under a rock since 1900 could be interpreted as a self-deprecating acknowledgment that they may have been out of touch with the current state of cinema, making the movie's freshness and originality all the more impressive.\n",
            "</positive-argument>\n",
            "\n",
            "<negative-argument>\n",
            "- The reviewer's comment about living under a rock since 1900 could be seen as a sarcastic or dismissive remark, implying that the movie's \"freshness and originality\" are not actually that impressive or noteworthy.\n",
            "- The review lacks any specific details or analysis about the movie, which could suggest that the reviewer's positive assessment is not well-founded or substantive.\n",
            "</negative-argument>\n",
            "\n",
            "Based on the review,\n"
          ]
        }
      ],
      "source": [
        "# System prompt\n",
        "SYSTEM_PROMPT = \"You are a savvy reader of movie reviews.\"\n",
        "\n",
        "# Prompt\n",
        "PROMPT = \"\"\"Is this review sentiment positive or negative? First, write the best arguments for each side in <positive-argument> and <negative-argument> XML tags, then answer.\n",
        "\n",
        "This movie blew my mind with its freshness and originality. In totally unrelated news, I have been living under a rock since 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT, SYSTEM_PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4p71sJ7LCku",
        "outputId": "9cf3e811-4b5d-4a74-c3d5-b62b184c2134"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<negative-argument>\n",
            "The statement \"I have been living under a rock since 1900\" could be interpreted as a negative sentiment, suggesting that the reviewer is out of touch with current trends and may not be a reliable source for evaluating the movie's freshness and originality.\n",
            "</negative-argument>\n",
            "\n",
            "<positive-argument>\n",
            "The reviewer's enthusiasm for the movie's \"freshness and originality\" suggests a positive sentiment. The reviewer seems to have been pleasantly surprised and impressed by the movie, which they describe as \"blowing their mind.\"\n",
            "</positive-argument>\n",
            "\n",
            "Based on the overall tone and content of the review, the sentiment is more positive than negative. The reviewer's positive comments about the movie's freshness and originality outweigh the potentially negative implication of being out of touch.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"\"\"Is this review sentiment negative or positive? First write the best arguments for each side in <negative-argument> and <positive-argument> XML tags, then answer.\n",
        "\n",
        "This movie blew my mind with its freshness and originality. Unrelatedly, I have been living under a rock since 1900.\"\"\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84-uUXeILCku",
        "outputId": "472e121e-a624-440c-8a85-570832d0cf27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a famous movie starring an actor born in 1956:\n",
            "\n",
            "The Shawshank Redemption (1994) starring Tim Robbins. Tim Robbins was born on October 16, 1958.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956.\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rzD9b404LCku",
        "outputId": "1c366406-4db7-482f-9c44-9266c1d94332"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's a brainstorm of some actors and their birth years:\n",
            "\n",
            "<brainstorm>\n",
            "- Tom Hanks (1956)\n",
            "- Denzel Washington (1954)\n",
            "- Julia Roberts (1967)\n",
            "- Harrison Ford (1942)\n",
            "- Meryl Streep (1949)\n",
            "</brainstorm>\n",
            "\n",
            "A famous movie starring an actor born in 1956 is:\n",
            "\n",
            "Forrest Gump, starring Tom Hanks.\n"
          ]
        }
      ],
      "source": [
        "# Prompt\n",
        "PROMPT = \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
        "\n",
        "# Print Claude's response\n",
        "print(get_completion(PROMPT))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN-2aOdILCkv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "conda_tensorflow2_p310",
      "language": "python",
      "name": "conda_tensorflow2_p310"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}